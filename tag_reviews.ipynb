{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste NLP - Birdie\n",
    "\n",
    "Autor: Rafael Augusto Monteiro\n",
    "\n",
    "rafaelmonteiro95@gmail.com\n",
    "\n",
    "\n",
    "## Enunciado do Problema\n",
    "Usando as ferramentas e bibliotecas que considerar mais adequadas, faça um programa que recebe um texto de reviews descritos em linguagem natural (PT-BR) e retorna a classe gramatical de cada palavra no texto\n",
    "\n",
    "Aplique seu programa sobre o conjunto de reviews no arquivo \"test.txt\"\n",
    "\n",
    "Por fim, identifique todos os trechos de reviews que seguem um dos padrões:\n",
    "\n",
    "SUBSTANTIVO + ADJETIVO ou\n",
    "\n",
    "SUBSTANTIVO + VERBO + ADJETIVO\n",
    "\n",
    "Por exemplo, em \"O celular tem uma tela boa\", o trecho \"tela boa\" deveria ser extraído porque segue o padrão SUBSTANTIVO + ADJETIVO.\n",
    "\n",
    "## Abordagem\n",
    "A abordagem descrita aqui usa o POS Tagger da biblioteca Spacy para etiquetar cada palavra com a sua classe gramatical. Spacy é uma biblioteca de processamento de linguagem natural de fácil acesso que possui modelos para o PT-BR.\n",
    "\n",
    "O procedimento consiste em etiquetar todas as palavras dos textos, gerar uma lista de tags, fazer o match entre cada padrão e as tags de cada linha, e extrair o texto onde houver match. Um caractere '/' é inserido após cada trecho extraído para separá-lo dos demais trechos extraídos daquele review.\n",
    "\n",
    "O resultado obtido é um arquivo de texto, com o mesmo número de linhas que o arquivo de entrada, contendo o texto extraído. As linhas que não tiveram texto extraído são mantidas em branco para facilitar o pareamento do arquivo iniciar e dos resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Req. 1\n",
    "Usando as ferramentas e bibliotecas que considerar mais adequadas, faça um programa que recebe um texto de reviews descritos em linguagem natural (PT-BR) e retorna a classe gramatical de cada palavra no texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tagger\n",
    "import spacy\n",
    "# Loading pt-br model\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_string(string, nlp = None):\n",
    "    # Loads the model if none is passed\n",
    "    if(nlp == None):\n",
    "        nlp = spacy.load('pt_core_news_sm')\n",
    "        \n",
    "    # Calls nlp on string, which returns a list of tokens. \n",
    "    # Then, creates two lists, one with words and another with the POS tag of each word\n",
    "    text, tags = zip(*[ (token.text, token.pos_) for token in nlp(string) ])\n",
    "    \n",
    "    # Returns the two lists\n",
    "    return (list(text), list(tags))\n",
    "\n",
    "\n",
    "def tag_list(list_of_strings, nlp = None):\n",
    "    result = []\n",
    "    # Loads the model if none is passed\n",
    "    if(nlp == None):\n",
    "        nlp = spacy.load('pt_core_news_sm')\n",
    "        \n",
    "    # calls the tagging function for each string in list_of_strings\n",
    "    tagged_strings = [tag_string(string, nlp) for string in list_of_strings]\n",
    "    \n",
    "    # returns the list of processed strings\n",
    "    return tagged_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com uma frase\n",
      "(['Isso', 'é', 'um', 'teste'], ['PRON', 'VERB', 'DET', 'NOUN'])\n",
      "\n",
      "Teste com lista de frases\n",
      "(['Isso', 'é', 'um', 'teste'], ['PRON', 'VERB', 'DET', 'NOUN'])\n",
      "(['Isso', 'é', 'mais', 'um', 'teste', 'muito', 'grande'], ['PRON', 'VERB', 'ADV', 'DET', 'NOUN', 'ADV', 'ADJ'])\n",
      "(['Vamos', 'testar', 'com', 'outra', 'frase'], ['AUX', 'VERB', 'ADP', 'DET', 'NOUN'])\n"
     ]
    }
   ],
   "source": [
    "string = \"Isso é um teste\"\n",
    "tagged_string = tag_string(string, nlp)\n",
    "print('Teste com uma frase')\n",
    "print(tagged_string, end='\\n\\n')\n",
    "\n",
    "string2 = \"Isso é mais um teste muito grande\"\n",
    "string3 = \"Vamos testar com outra frase\"\n",
    "tagged_list = tag_list([string, string2, string3], nlp)\n",
    "print('Teste com lista de frases')\n",
    "print(*tagged_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Req. 2\n",
    "Aplique seu programa sobre o conjunto de reviews no arquivo \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data.txt', 'r', encoding='utf8') as f:\n",
    "    reviews = f.read().split('\\n')\n",
    "    \n",
    "# tagging all reviews\n",
    "tagged_result = tag_list(reviews, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Muito', 'bonito', '!'], ['ADV', 'NOUN', 'PUNCT']),\n",
       " (['Muito', 'bom'], ['ADV', 'ADJ']),\n",
       " (['Ótimo', 'livro'], ['ADJ', 'NOUN']),\n",
       " (['Excelente'], ['ADJ']),\n",
       " (['Surpreso'], ['PROPN'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Req 3\n",
    "Por fim, identifique todos os trechos de reviews que seguem um dos padrões:\n",
    "\n",
    "SUBSTANTIVO + ADJETIVO ou\n",
    "\n",
    "SUBSTANTIVO + VERBO + ADJETIVO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the text in tagged_string matching the patterns given\n",
    "# Returns a string with text that matches patterns\n",
    "# Returns an empty string if text does not match\n",
    "def extract_patterns(tagged_string, patterns):\n",
    "    result = []\n",
    "    # unpacking tags and texts from tagged_strings\n",
    "    text, tags = tagged_string\n",
    "    # checking for each pattern\n",
    "    for pattern in patterns:\n",
    "        # uses a \"sliding window\" method for checking the pattern\n",
    "        stride = len(pattern)\n",
    "        for i in range(len(tags) - stride + 1):\n",
    "            if(tags[i:i+stride] == pattern):\n",
    "                result += text[i:i+stride] + ['/']\n",
    "    # joins all the matching text into a string\n",
    "    return ' '.join(result)\n",
    "\n",
    "# function that extracts the text from a list of tagged_strings matching the patterns given\n",
    "def extract_patterns_from_list(tagged_strings, patterns):\n",
    "    return [extract_patterns(string, patterns)  for string in tagged_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padrões: [['NOUN', 'ADJ'], ['NOUN', 'VERB', 'ADJ']]\n",
      "\n",
      "Review 6: Muito bom\n",
      "Tags: ['ADV', 'ADJ']\n",
      "Texto extraído: \n",
      "\n",
      "Review 6: Leitura excelente\n",
      "Tags: ['NOUN', 'ADJ']\n",
      "Texto extraído: Leitura excelente /\n"
     ]
    }
   ],
   "source": [
    "patterns = [['NOUN','ADJ'],['NOUN', 'VERB', 'ADJ']]\n",
    "print(f'Padrões: {patterns}',end='\\n\\n')\n",
    "\n",
    "# Executando em dois exemplos\n",
    "print(f'Review 6: {\" \".join(tagged_result[6][0])}')\n",
    "print(f'Tags: {tagged_result[6][1]}')\n",
    "print(f'Texto extraído: {extract_patterns(tagged_result[6],patterns)}', end='\\n\\n')\n",
    "\n",
    "print(f'Review 6: {\" \".join(tagged_result[12][0])}')\n",
    "print(f'Tags: {tagged_result[12][1]}')\n",
    "print(f'Texto extraído: {extract_patterns(tagged_result[12],patterns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting text from all reviews\n",
    "extracted_texts = extract_patterns_from_list(tagged_result, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review  0: \n",
      "Review  1: \n",
      "Review  2: \n",
      "Review  3: \n",
      "Review  4: \n",
      "Review  5: \n",
      "Review  6: \n",
      "Review  7: preço bacana /\n",
      "Review  8: \n",
      "Review  9: \n",
      "Review 10: \n",
      "Review 11: Fixação ruim /\n",
      "Review 12: zoom é ruim /\n",
      "Review 13: \n",
      "Review 14: \n",
      "Review 15: Entrega rápida / leitura ótima /\n",
      "Review 16: \n",
      "Review 17: \n",
      "Review 18: \n",
      "Review 19: \n",
      "Review 20: \n",
      "Review 21: \n",
      "Review 22: ficção científica /\n",
      "Review 23: \n",
      "Review 24: \n",
      "Review 25: \n",
      "Review 26: \n",
      "Review 27: \n",
      "Review 28: \n",
      "Review 29: \n",
      "Review 30: \n",
      "Review 31: \n",
      "Review 32: Produto ótimo /\n",
      "Review 33: \n",
      "Review 34: \n",
      "Review 35: \n",
      "Review 36: \n",
      "Review 37: \n",
      "Review 38: \n",
      "Review 39: \n",
      "Review 40: teclas básicas /\n",
      "Review 41: \n",
      "Review 42: \n",
      "Review 43: \n",
      "Review 44: \n",
      "Review 45: \n",
      "Review 46: \n",
      "Review 47: \n",
      "Review 48: Produto menor /\n",
      "Review 49: Entrega rápida / produto bom /\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(extracted_texts[100:150]):\n",
    "    print(f'Review {i:2d}: {element}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results in a file\n",
    "with open('result.txt','w', encoding='utf8') as f:\n",
    "    print(*extracted_texts, sep='\\n', end='', file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
